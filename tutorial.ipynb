{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-29T16:21:21.917180Z",
     "start_time": "2023-12-29T16:21:20.890631Z"
    }
   },
   "outputs": [],
   "source": [
    "# 필요한 라이브러리 불러오기\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "device = torch.device(\"cuda\")  # 학습에 사용할 장치 (GPU 또는 CPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3ab83c2a9193b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-29T16:21:23.179905Z",
     "start_time": "2023-12-29T16:21:23.160910Z"
    }
   },
   "outputs": [],
   "source": [
    "# MNIST 데이터셋 불러오기\n",
    "\n",
    "dataset = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    transform=transforms.ToTensor(),\n",
    "    download=True\n",
    ")\n",
    "\n",
    "batch_size = 1024  # 한 번에 학습할 데이터 개수\n",
    "\n",
    "dataloaders = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=2,\n",
    "    pin_memory=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6589abe76be870e4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-29T16:21:24.265677Z",
     "start_time": "2023-12-29T16:21:24.006818Z"
    }
   },
   "outputs": [],
   "source": [
    "# MNIST 데이터셋 시각화\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_mnist(img, lbl):\n",
    "    plt.imshow(img[0], cmap=\"binary\")\n",
    "    plt.title(lbl)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "image, label = dataset[0]\n",
    "plot_mnist(image, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad15d5fcc41d43b6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-29T16:21:24.999275Z",
     "start_time": "2023-12-29T16:21:24.996173Z"
    }
   },
   "outputs": [],
   "source": [
    "# AutoEncoder 모델 구현\n",
    "\n",
    "\n",
    "space_size = 10  # Latent space 차원\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(784, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, space_size),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.mlp(x)\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(space_size, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 784),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.mlp(x)\n",
    "\n",
    "\n",
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, enc, dec):\n",
    "        super().__init__()\n",
    "        self.encoder = enc\n",
    "        self.decoder = dec\n",
    "\n",
    "        # He initialization\n",
    "        for name, param in self.named_parameters():\n",
    "            if \"weight\" in name:\n",
    "                nn.init.kaiming_uniform_(param, nonlinearity=\"relu\")\n",
    "            elif \"bias\" in name:\n",
    "                nn.init.zeros_(param)\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1f12c293995753",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-29T16:21:26.170955Z",
     "start_time": "2023-12-29T16:21:26.143853Z"
    }
   },
   "outputs": [],
   "source": [
    "# AutoEncoder 모델 생성\n",
    "\n",
    "\n",
    "encoder = Encoder()\n",
    "decoder = Decoder()\n",
    "autoencoder = AutoEncoder(encoder, decoder).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b1dc5202535b34",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-29T16:22:31.925178Z",
     "start_time": "2023-12-29T16:21:28.161616Z"
    }
   },
   "outputs": [],
   "source": [
    "# AutoEncoder 모델 학습\n",
    "\n",
    "\n",
    "epochs = 30\n",
    "learning_rate = 1e-3\n",
    "optimizer = torch.optim.Adam(autoencoder.parameters(), lr=learning_rate)\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "for epoch in (pbar := tqdm(range(epochs))):\n",
    "    for data, _ in dataloaders:\n",
    "        data = data.view(-1, 28 * 28).to(device)  # 이미지를 1차원 벡터로 변환\n",
    "\n",
    "        optimizer.zero_grad()  # 이전 학습 단계에서 계산된 기울기 지우기\n",
    "\n",
    "        output = autoencoder(data)  # AutoEncoder 모델의 출력 계산\n",
    "\n",
    "        loss = F.mse_loss(output, data)  # 출력과 입력의 차이를 계산하여 오차 계산\n",
    "        loss.backward()  # 연쇄법칙을 사용하여 오차를 각 파라미터로 전파\n",
    "\n",
    "        optimizer.step()  # 파라미터 업데이트 (경사하강법)\n",
    "\n",
    "        pbar.set_postfix(loss=loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0f2c5231fb31be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-29T16:22:46.138193Z",
     "start_time": "2023-12-29T16:22:45.967747Z"
    }
   },
   "outputs": [],
   "source": [
    "# 학습된 AutoEncoder 모델 결과 확인\n",
    "\n",
    "\n",
    "\n",
    "def plot_reconstructed(img, lbl, pred):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "    ax1.imshow(img[0], cmap=\"binary\")\n",
    "    ax1.set_title(f\"Original {lbl}\")\n",
    "    ax2.imshow(pred[0].detach().cpu().numpy().reshape(28, 28), cmap=\"binary\")\n",
    "    ax2.set_title(f\"Reconstructed {lbl}\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "image, label = dataset[7]\n",
    "output = autoencoder(image.view(-1, 28 * 28).to(device))\n",
    "plot_reconstructed(image, label, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266f1ad185c6a45a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-29T16:22:49.589689Z",
     "start_time": "2023-12-29T16:22:49.582055Z"
    }
   },
   "outputs": [],
   "source": [
    "# Text to Image 모델 구현\n",
    "\n",
    "\n",
    "embedding_size = 10  # 단어 임베딩 차원\n",
    "\n",
    "\n",
    "class TextEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(embedding_size, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, space_size),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        # He initialization\n",
    "        for name, param in self.named_parameters():\n",
    "            if \"weight\" in name:\n",
    "                nn.init.kaiming_uniform_(param, nonlinearity=\"relu\")\n",
    "            elif \"bias\" in name:\n",
    "                nn.init.zeros_(param)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.mlp(x)\n",
    "\n",
    "\n",
    "class TextToImage(nn.Module):\n",
    "    def __init__(self, text_enc, dec):\n",
    "        super().__init__()\n",
    "        self.text_encoder = text_enc\n",
    "        self.decoder = dec\n",
    "\n",
    "        # AutoEncoder의 Decoder는 학습되지 않도록 함\n",
    "        self.decoder.eval()\n",
    "        for param in self.decoder.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.text_encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2fc1cff45f01142",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-29T16:23:10.904649Z",
     "start_time": "2023-12-29T16:23:10.901608Z"
    }
   },
   "outputs": [],
   "source": [
    "# 텍스트(숫자)를 원-핫 벡터로 변환\n",
    "\n",
    "\n",
    "\n",
    "def number_to_one_hot(number):\n",
    "    one_hot_vec = torch.zeros(embedding_size)\n",
    "    one_hot_vec[int(number)] = 1\n",
    "    return one_hot_vec.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875cef1bc10a4cc7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-29T16:23:16.904547Z",
     "start_time": "2023-12-29T16:23:16.900229Z"
    }
   },
   "outputs": [],
   "source": [
    "# Text to Image 모델 생성\n",
    "\n",
    "\n",
    "text_encoder = TextEncoder()\n",
    "model = TextToImage(\n",
    "    text_encoder,\n",
    "    decoder,  # AutoEncoder의 Decoder를 사용!\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97dbc5de44451dfb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-29T16:23:38.789883Z",
     "start_time": "2023-12-29T16:23:18.246967Z"
    }
   },
   "outputs": [],
   "source": [
    "# Text to Image 모델 학습\n",
    "\n",
    "\n",
    "epochs = 10\n",
    "learning_rate = 1e-3\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in (pbar := tqdm(range(epochs))):\n",
    "    for data, label in dataloaders:\n",
    "        data = data.view(-1, 28 * 28).to(device)\n",
    "        one_hot = torch.stack([number_to_one_hot(number) for number in label]).to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model.text_encoder(one_hot)\n",
    "        target = autoencoder.encoder(data)\n",
    "        \n",
    "        loss = F.mse_loss(output, target)\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        pbar.set_postfix(loss=loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e84c5e75356dee6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-29T16:23:58.133394Z",
     "start_time": "2023-12-29T16:23:54.089932Z"
    }
   },
   "outputs": [],
   "source": [
    "# 학습된 Text to Image 모델 결과 확인\n",
    "\n",
    "\n",
    "\n",
    "def text_to_image(text):\n",
    "    one_hot = number_to_one_hot(int(text))\n",
    "\n",
    "    result = model(one_hot)\n",
    "    result = result.detach().cpu().numpy().reshape(28, 28)\n",
    "\n",
    "    plt.imshow(result, cmap=\"binary\")\n",
    "    plt.title(f\"Text to Image: {text}\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "number = input(\"그릴 숫자 입력: \")\n",
    "text_to_image(number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144fc220abdda6ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
